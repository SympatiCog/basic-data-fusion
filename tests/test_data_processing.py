"""
Tests for data processing functionality.
"""
import os

# Import the functions we want to test
import sys
import tempfile

import pandas as pd
import pytest

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from main import (
    Config,
    MergeKeys,
    calculate_numeric_ranges_fast,
    enwiden_longitudinal_data,
    extract_column_metadata_fast,
    get_unique_session_values,
    is_numeric_column,
)


class TestEnwidenLongitudinalData:
    """Test the enwiden_longitudinal_data function for pivoting long to wide format."""

    @pytest.fixture
    def longitudinal_merge_keys(self):
        """Longitudinal merge keys for testing."""
        return MergeKeys(
            primary_id='ursi',
            session_id='session_num',
            composite_id='customID',
            is_longitudinal=True
        )

    @pytest.fixture
    def cross_sectional_merge_keys(self):
        """Cross-sectional merge keys for testing."""
        return MergeKeys(
            primary_id='ursi',
            is_longitudinal=False
        )

    @pytest.fixture
    def sample_longitudinal_data(self):
        """Sample longitudinal data for testing."""
        return pd.DataFrame({
            'ursi': ['SUB001', 'SUB001', 'SUB002', 'SUB002', 'SUB003', 'SUB003'],
            'session_num': ['BAS1', 'BAS2', 'BAS1', 'BAS2', 'BAS1', 'BAS2'],
            'customID': ['SUB001_BAS1', 'SUB001_BAS2', 'SUB002_BAS1', 'SUB002_BAS2', 'SUB003_BAS1', 'SUB003_BAS2'],
            'age': [25, 25, 30, 30, 28, 28],  # Static - same across sessions
            'sex': [1.0, 1.0, 2.0, 2.0, 1.0, 1.0],  # Static - same across sessions
            'working_memory': [105, 108, 98, 102, 112, 115],  # Dynamic - changes across sessions
            'rt_congruent': [500, 480, 520, 510, 490, 470]  # Dynamic - changes across sessions
        })

    def test_enwiden_cross_sectional_data(self, cross_sectional_merge_keys, sample_longitudinal_data):
        """Test that cross-sectional data is returned unchanged."""
        selected_columns = {
            'demographics': ['ursi', 'age', 'sex'],
            'cognitive': ['working_memory']
        }

        result = enwiden_longitudinal_data(
            sample_longitudinal_data,
            cross_sectional_merge_keys,
            selected_columns
        )

        # Should return the original dataframe unchanged
        pd.testing.assert_frame_equal(result, sample_longitudinal_data)

    def test_enwiden_basic_longitudinal_pivot(self, longitudinal_merge_keys, sample_longitudinal_data):
        """Test basic longitudinal data pivoting."""
        selected_columns = {
            'demographics': ['ursi', 'age', 'sex'],
            'cognitive': ['working_memory', 'rt_congruent']
        }

        result = enwiden_longitudinal_data(
            sample_longitudinal_data,
            longitudinal_merge_keys,
            selected_columns
        )

        # Check that we have one row per participant
        assert len(result) == 3  # 3 unique participants
        assert len(result['ursi'].unique()) == 3

        # Check that static columns are preserved
        assert 'age' in result.columns
        assert 'sex' in result.columns

        # Check that dynamic columns are pivoted with session suffixes
        assert 'working_memory_BAS1' in result.columns
        assert 'working_memory_BAS2' in result.columns
        assert 'rt_congruent_BAS1' in result.columns
        assert 'rt_congruent_BAS2' in result.columns

        # Check specific values for first participant
        sub001_row = result[result['ursi'] == 'SUB001'].iloc[0]
        assert sub001_row['age'] == 25
        assert sub001_row['working_memory_BAS1'] == 105
        assert sub001_row['working_memory_BAS2'] == 108
        assert sub001_row['rt_congruent_BAS1'] == 500
        assert sub001_row['rt_congruent_BAS2'] == 480

    def test_enwiden_static_vs_dynamic_detection(self, longitudinal_merge_keys):
        """Test detection of static vs dynamic columns."""
        # Data where some columns are truly static, others dynamic
        data = pd.DataFrame({
            'ursi': ['SUB001', 'SUB001', 'SUB002', 'SUB002'],
            'session_num': ['BAS1', 'BAS2', 'BAS1', 'BAS2'],
            'customID': ['SUB001_BAS1', 'SUB001_BAS2', 'SUB002_BAS1', 'SUB002_BAS2'],
            'age': [25, 25, 30, 30],  # Static - same value within participant
            'height': [165.5, 165.5, 178.0, 178.0],  # Static - same value within participant
            'weight': [60.2, 61.1, 75.8, 76.2],  # Dynamic - changes between sessions
            'score': [85, 90, 88, 92]  # Dynamic - changes between sessions
        })

        selected_columns = {
            'demographics': ['ursi', 'age', 'height', 'weight'],
            'assessment': ['score']
        }

        result = enwiden_longitudinal_data(data, longitudinal_merge_keys, selected_columns)

        # Static columns should remain as single columns
        assert 'age' in result.columns
        assert 'height' in result.columns
        assert 'age_BAS1' not in result.columns  # Should not be pivoted
        assert 'height_BAS1' not in result.columns  # Should not be pivoted

        # Dynamic columns should be pivoted
        assert 'weight_BAS1' in result.columns
        assert 'weight_BAS2' in result.columns
        assert 'score_BAS1' in result.columns
        assert 'score_BAS2' in result.columns
        assert 'weight' not in result.columns  # Original should be removed
        assert 'score' not in result.columns  # Original should be removed

    def test_enwiden_missing_session_data(self, longitudinal_merge_keys):
        """Test handling of missing data for some sessions."""
        data = pd.DataFrame({
            'ursi': ['SUB001', 'SUB001', 'SUB002'],  # SUB002 missing BAS2
            'session_num': ['BAS1', 'BAS2', 'BAS1'],
            'customID': ['SUB001_BAS1', 'SUB001_BAS2', 'SUB002_BAS1'],
            'age': [25, 25, 30],
            'score': [85, 90, 88]
        })

        selected_columns = {
            'assessment': ['score']
        }

        result = enwiden_longitudinal_data(data, longitudinal_merge_keys, selected_columns)

        # Should have 2 rows (one per participant)
        assert len(result) == 2

        # SUB001 should have both sessions
        sub001 = result[result['ursi'] == 'SUB001'].iloc[0]
        assert sub001['score_BAS1'] == 85
        assert sub001['score_BAS2'] == 90

        # SUB002 should have BAS1 data and NaN for BAS2
        sub002 = result[result['ursi'] == 'SUB002'].iloc[0]
        assert sub002['score_BAS1'] == 88
        assert pd.isna(sub002['score_BAS2'])

    def test_enwiden_empty_dataframe(self, longitudinal_merge_keys):
        """Test handling of empty input dataframe."""
        empty_df = pd.DataFrame()
        selected_columns = {'demographics': ['ursi']}

        result = enwiden_longitudinal_data(empty_df, longitudinal_merge_keys, selected_columns)

        assert result.empty
        assert isinstance(result, pd.DataFrame)

    def test_enwiden_single_session(self, longitudinal_merge_keys):
        """Test handling of data with only one session."""
        data = pd.DataFrame({
            'ursi': ['SUB001', 'SUB002'],
            'session_num': ['BAS1', 'BAS1'],
            'customID': ['SUB001_BAS1', 'SUB002_BAS1'],
            'age': [25, 30],
            'score': [85, 88]
        })

        selected_columns = {'assessment': ['score']}

        result = enwiden_longitudinal_data(data, longitudinal_merge_keys, selected_columns)

        # Should still work, but since there's only one session and no variation,
        # columns should not be pivoted
        assert len(result) == 2
        assert 'score' in result.columns  # Should keep original column name
        assert 'score_BAS1' not in result.columns  # Should not pivot single session

    def test_enwiden_static_columns_not_pivoted(self, longitudinal_merge_keys):
        """Test that static columns (no variation between sessions) are not pivoted."""
        data = pd.DataFrame({
            'ursi': ['SUB001', 'SUB001', 'SUB002', 'SUB002'],
            'session_num': ['BAS1', 'BAS2', 'BAS1', 'BAS2'],
            'customID': ['SUB001_BAS1', 'SUB001_BAS2', 'SUB002_BAS1', 'SUB002_BAS2'],
            'age': [25, 25, 30, 30],  # Static - same value for each participant
            'static_score': [85, 85, 88, 88]  # Static - no change between sessions
        })

        selected_columns = {'assessment': ['static_score']}

        result = enwiden_longitudinal_data(data, longitudinal_merge_keys, selected_columns)

        # Static columns should not be pivoted
        assert len(result) == 2
        assert 'static_score' in result.columns
        assert 'static_score_BAS1' not in result.columns
        assert 'static_score_BAS2' not in result.columns


class TestGetUniqueSessionValues:
    """Test the get_unique_session_values function."""

    @pytest.fixture
    def temp_data_dir(self):
        """Create a temporary directory with sample CSV files."""
        with tempfile.TemporaryDirectory() as temp_dir:
            # Create demographics.csv
            demo_data = pd.DataFrame({
                'ursi': ['SUB001', 'SUB001', 'SUB002', 'SUB002'],
                'session_num': ['BAS1', 'BAS2', 'BAS1', 'FLU1'],
                'age': [25, 25, 30, 30]
            })
            demo_data.to_csv(os.path.join(temp_dir, 'demographics.csv'), index=False)

            # Create cognitive.csv
            cog_data = pd.DataFrame({
                'ursi': ['SUB001', 'SUB001', 'SUB003'],
                'session_num': ['BAS1', 'FLU2', 'BAS1'],
                'working_memory': [105, 108, 112]
            })
            cog_data.to_csv(os.path.join(temp_dir, 'cognitive.csv'), index=False)

            # Create file without session column
            nosession_data = pd.DataFrame({
                'ursi': ['SUB001', 'SUB002'],
                'height': [165, 178]
            })
            nosession_data.to_csv(os.path.join(temp_dir, 'measurements.csv'), index=False)

            yield temp_dir

    def test_get_unique_session_values(self, temp_data_dir):
        """Test extraction of unique session values from multiple files."""
        merge_keys = MergeKeys(
            primary_id='ursi',
            session_id='session_num',
            is_longitudinal=True
        )

        sessions = get_unique_session_values(temp_data_dir, merge_keys)

        # Should find all unique sessions across all files
        expected_sessions = ['BAS1', 'BAS2', 'FLU1', 'FLU2']
        assert sorted(sessions) == sorted(expected_sessions)

    def test_get_unique_session_values_no_session_column(self, temp_data_dir):
        """Test when merge_keys doesn't have session column."""
        merge_keys = MergeKeys(
            primary_id='ursi',
            is_longitudinal=False
        )

        sessions = get_unique_session_values(temp_data_dir, merge_keys)

        # Should return empty list when no session column
        assert sessions == []

    def test_get_unique_session_values_empty_dir(self):
        """Test with empty data directory."""
        with tempfile.TemporaryDirectory() as temp_dir:
            merge_keys = MergeKeys(
                primary_id='ursi',
                session_id='session_num',
                is_longitudinal=True
            )

            sessions = get_unique_session_values(temp_dir, merge_keys)

            assert sessions == []


class TestIsNumericColumn:
    """Test the is_numeric_column function."""

    def test_integer_types(self):
        """Test detection of integer data types."""
        assert is_numeric_column('int64')
        assert is_numeric_column('int32')
        assert is_numeric_column('int16')
        assert is_numeric_column('int8')
        assert is_numeric_column('uint64')
        assert is_numeric_column('uint32')

    def test_float_types(self):
        """Test detection of float data types."""
        assert is_numeric_column('float64')
        assert is_numeric_column('float32')
        assert is_numeric_column('float16')

    def test_non_numeric_types(self):
        """Test rejection of non-numeric data types."""
        assert not is_numeric_column('object')
        assert not is_numeric_column('string')
        assert not is_numeric_column('bool')
        assert not is_numeric_column('datetime64')
        assert not is_numeric_column('category')

    def test_case_variations(self):
        """Test handling of case variations in type names."""
        # Function is case-sensitive and expects lowercase
        assert is_numeric_column('int64')
        assert is_numeric_column('float32')
        assert not is_numeric_column('object')

        # Uppercase should return False (case-sensitive)
        assert not is_numeric_column('INT64')
        assert not is_numeric_column('OBJECT')


class TestExtractColumnMetadataFast:
    """Test the extract_column_metadata_fast function."""

    @pytest.fixture
    def sample_csv_file(self):
        """Create a sample CSV file for testing."""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            f.write("ursi,age,sex,score,notes\n")
            f.write("SUB001,25,Female,85.5,Good performance\n")
            f.write("SUB002,30,Male,92.0,Excellent\n")
            f.write("SUB003,28,Female,78.2,Average\n")
            temp_path = f.name

        yield temp_path
        os.unlink(temp_path)

    def test_extract_column_metadata(self, sample_csv_file):
        """Test extraction of column metadata."""
        merge_keys = MergeKeys(primary_id='ursi', is_longitudinal=False)

        columns, dtypes = extract_column_metadata_fast(
            sample_csv_file,
            table_name='test_table',
            is_demo_table=False,
            merge_keys=merge_keys
        )

        # Function filters out ID columns, so ursi is not included
        expected_columns = ['age', 'sex', 'score', 'notes']
        assert columns == expected_columns

        # Check that dtypes is a dict with correct structure
        # Dtypes are prefixed with table name
        assert isinstance(dtypes, dict)
        assert len(dtypes) == len(expected_columns)

        # Check that numeric columns are detected (with table prefix)
        assert 'int' in str(dtypes['test_table.age']).lower() or 'float' in str(dtypes['test_table.age']).lower()
        assert 'float' in str(dtypes['test_table.score']).lower()
        assert 'object' in str(dtypes['test_table.sex']).lower() or 'string' in str(dtypes['test_table.sex']).lower()

    def test_extract_column_metadata_nonexistent_file(self):
        """Test handling of nonexistent file."""
        merge_keys = MergeKeys(primary_id='ursi', is_longitudinal=False)

        with pytest.raises(FileNotFoundError):
            extract_column_metadata_fast(
                '/nonexistent/file.csv',
                table_name='test_table',
                is_demo_table=False,
                merge_keys=merge_keys
            )


class TestCalculateNumericRangesFast:
    """Test the calculate_numeric_ranges_fast function."""

    @pytest.fixture
    def numeric_csv_file(self):
        """Create a CSV file with numeric data for testing."""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            f.write("ursi,age,score,height,weight\n")
            for i in range(100):  # Create enough data to test chunking
                f.write(f"SUB{i:03d},{20+i//5},{50+i},{160+i//10},{50+i//2}\n")
            temp_path = f.name

        yield temp_path
        os.unlink(temp_path)

    def test_calculate_numeric_ranges(self, numeric_csv_file):
        """Test calculation of numeric ranges."""
        merge_keys = MergeKeys(primary_id='ursi', is_longitudinal=False)

        # First get the column dtypes
        columns, dtypes = extract_column_metadata_fast(
            numeric_csv_file,
            table_name='test_table',
            is_demo_table=False,
            merge_keys=merge_keys
        )

        ranges = calculate_numeric_ranges_fast(
            numeric_csv_file,
            table_name='test_table',
            is_demo_table=False,
            column_dtypes=dtypes,
            merge_keys=merge_keys
        )

        assert isinstance(ranges, dict)

        # Check that numeric columns are included
        # Note: both dtypes and ranges keys are prefixed with table name
        numeric_cols = [col for col in columns if is_numeric_column(dtypes[f'test_table.{col}'])]
        for col in numeric_cols:
            if col in ['age', 'score', 'height', 'weight']:  # Expected numeric columns
                assert f'test_table.{col}' in ranges  # Range keys are also prefixed

        # Check that non-numeric columns are excluded
        assert 'ursi' not in ranges  # ID column filtered out
        assert 'test_table.ursi' not in ranges  # ID column filtered out

        # Check range structure
        for _col, (min_val, max_val) in ranges.items():
            assert isinstance(min_val, (int, float))
            assert isinstance(max_val, (int, float))
            assert min_val <= max_val

        # Check specific ranges based on test data (with table prefix)
        if 'test_table.age' in ranges:
            assert ranges['test_table.age'][0] == 20  # min
            assert ranges['test_table.age'][1] == 39  # max (20 + 99//5)
        if 'test_table.score' in ranges:
            assert ranges['test_table.score'][0] == 50  # min
            assert ranges['test_table.score'][1] == 149  # max (50 + 99)

    def test_calculate_numeric_ranges_no_numeric_columns(self):
        """Test with file containing no numeric columns."""
        with tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False) as f:
            f.write("ursi,name,category\n")
            f.write("SUB001,John,A\n")
            f.write("SUB002,Jane,B\n")
            temp_path = f.name

        try:
            merge_keys = MergeKeys(primary_id='ursi', is_longitudinal=False)

            # Get column dtypes first
            columns, dtypes = extract_column_metadata_fast(
                temp_path,
                table_name='test_table',
                is_demo_table=False,
                merge_keys=merge_keys
            )

            ranges = calculate_numeric_ranges_fast(
                temp_path,
                table_name='test_table',
                is_demo_table=False,
                column_dtypes=dtypes,
                merge_keys=merge_keys
            )
            assert ranges == {}
        finally:
            os.unlink(temp_path)


class TestDataTypeHandling:
    """Test data type handling and conversion functions."""

    def test_sex_mapping_configuration(self):
        """Test that sex mapping is properly configured."""
        expected_mapping = {
            'Female': 1.0,
            'Male': 2.0,
            'Other': 3.0,
            'Unspecified': 0.0
        }

        assert hasattr(Config, 'SEX_MAPPING')
        assert Config.SEX_MAPPING == expected_mapping

    def test_sex_options_configuration(self):
        """Test that sex options are properly configured."""
        assert hasattr(Config, 'SEX_OPTIONS')
        assert hasattr(Config, 'DEFAULT_SEX_SELECTION')

        expected_options = ['Female', 'Male', 'Other', 'Unspecified']
        assert Config.SEX_OPTIONS == expected_options

        # Default selection should be subset of options
        assert all(option in Config.SEX_OPTIONS for option in Config.DEFAULT_SEX_SELECTION)

    def test_sex_mapping_numeric_conversion(self):
        """Test numeric conversion using sex mapping."""
        # Simulate the conversion logic used in generate_base_query_logic
        sex_filter = ['Female', 'Male']
        numeric_sex_values = [Config.SEX_MAPPING[s] for s in sex_filter]

        expected_values = [1.0, 2.0]
        assert numeric_sex_values == expected_values

    def test_sex_mapping_all_values(self):
        """Test conversion of all sex mapping values."""
        for _sex_str, expected_numeric in Config.SEX_MAPPING.items():
            assert isinstance(expected_numeric, float)
            assert expected_numeric >= 0.0
